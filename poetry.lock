[[package]]
name = "py4j"
version = "0.10.9"
description = "Enables Python programs to dynamically access arbitrary Java objects"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pyspark"
version = "3.1.3"
description = "Apache Spark Python API"
category = "main"
optional = false
python-versions = ">=3.6"

[package.dependencies]
py4j = "0.10.9"

[package.extras]
ml = ["numpy (>=1.7)"]
mllib = ["numpy (>=1.7)"]
sql = ["pandas (>=0.23.2)", "pyarrow (>=1.0.0)"]

[[package]]
name = "spark"
version = "0.2.1"
description = "A Super-Small, Super-Fast, and Super-Easy web framework"
category = "main"
optional = false
python-versions = "*"

[metadata]
lock-version = "1.1"
python-versions = "^3.10"
content-hash = "65a4b62cabd74e1ed4e00d18cc282672cf9ac6906c34f897d63a851a23572600"

[metadata.files]
py4j = [
    {file = "py4j-0.10.9-py2.py3-none-any.whl", hash = "sha256:859ba728a7bb43e9c2bf058832759fb97a598bb28cc12f34f5fc4abdec08ede6"},
    {file = "py4j-0.10.9.tar.gz", hash = "sha256:36ec57f43ff8ced260a18aa9a4e46c3500a730cac8860e259cbaa546c2b9db2f"},
]
pyspark = [
    {file = "pyspark-3.1.3.tar.gz", hash = "sha256:39ac641ef5559a3d1286154779fc990316e9934520853615ae4785c1af52d14b"},
]
spark = [
    {file = "spark-0.2.1.tar.gz", hash = "sha256:df499b57d30178c6d32dbda2af188b9833a261a70ccd262126ed7b415d9e36d1"},
]
